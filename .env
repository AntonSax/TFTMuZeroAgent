NUM_CPUS=28
GPU_SIZE_PER_WORKER=0.2
STORAGE_GPU_SIZE=0.1
BUFFER_GPU_SIZE=0.02
TRAINER_GPU_SIZE=0.2

DEVICE="cuda"
IMITATION=True
CHAMP_DECIDER=False

ACTIONS_PER_TURN=15
CONCURRENT_GAMES=4
NUM_PLAYERS=8

AUTO_BATTLER_PERCENTAGE=0

DEBUG=True
CHECKPOINT_STEPS=100

STARTING_EPISODE=0

HIDDEN_STATE_SIZE=1024
NUM_RNN_CELLS=2
LAYER_HIDDEN_SIZE=1024
ROOT_DIRICHLET_ALPHA=1.0
ROOT_EXPLORATION_FRACTION=0.25
VISIT_TEMPERATURE=1.0
MINIMUM_REWARD=-300.0
MAXIMUM_REWARD=300.0
PB_C_BASE=19652
PB_C_INIT=1.25
DISCOUNT=0.997
TRAINING_STEPS=1e
OBSERVATION_SIZE=10432
OBSERVATION_TIME_STEPS=4
OBSERVATION_TIME_STEP_INTERVAL=5
INPUT_TENSOR_SHAPE=np.array([OBSERVATION_SIZE])
ACTION_ENCODING_SIZE=1045
ACTION_CONCAT_SIZE=83
# 57 is the number of champions in set 4. Don't want to add an import to the STATS in the simulator in a config file

# Number of categories for each trait tier. Emperor for example has 2, no emperors or 1.
TIERS_FLATTEN_LENGTH=97
CHANCE_BUFFER_SEND=1
GLOBAL_BUFFER_SIZE=15000
ITEM_POSITIONING_BUFFER_SIZE=2000
MINIMUM_POP_AMOUNT=100

# ACTION_DIM = 10
ENCODER_NUM_STEPS=601
SELECTED_SAMPLES=True
MAX_GRAD_NORM=5

N_HEAD_HIDDEN_LAYERS=2

# Set to -1 to turn off.
TD_STEPS=-1

NUM_SAMPLES=30
NUM_SIMULATIONS=50

# This should be 1000 + because we want to be sampling everything when using priority.
# To change, look into the code in replay_muzero_buffer
SAMPLES_PER_PLAYER=1000

# For default agent, this needs to be low because there often isn't many samples per game.
UNROLL_STEPS=5

### TRAINING ###
BATCH_SIZE=1024
INIT_LEARNING_RATE=0.01
LEARNING_RATE_DECAY=int(350e3)
LR_DECAY_FUNCTION=0.1
WEIGHT_DECAY=1e-5
REWARD_LOSS_SCALING=1
POLICY_LOSS_SCALING=1
VALUE_LOSS_SCALING=1
GAME_METRICS_SCALING=0.2

